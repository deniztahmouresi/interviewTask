{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMU6JcLyzchtoXKIOODEmqH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deniztahmouresi/interviewTask/blob/develop/InterviewTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp-atSFrdNJJ",
        "outputId": "5873f9bb-e730-4b1b-c659-f2df9d4a7a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "drive.mount('/content/drive')\n",
        "dataset = np.load('/content/drive/MyDrive/Colab Notebooks/interviewTask/data.npz')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import signal\n",
        "\n",
        "x_train = dataset['X_train']\n",
        "y_train = dataset['y_train']\n",
        "x_test = dataset['X_test']\n",
        "y_test = dataset['y_test']\n",
        "\n",
        "X_train = np.ndarray(shape=(len(x_train),28, 28) , dtype=int)\n",
        "i = 0\n",
        "for img in x_train:\n",
        "  X_train[i] = signal.medfilt2d(img)\n",
        "  i += 1\n",
        "X_test = np.ndarray(shape=(len(x_test),28, 28) , dtype=int)\n",
        "i = 0\n",
        "for img in x_test:\n",
        "  X_test[i] = signal.medfilt2d(img)\n",
        "  i += 1\n",
        "\n",
        "# Data normalize to the [0, 1] range\n",
        "X_train = X_train.astype(\"float32\") / 255\n",
        "X_test = X_test.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "vBUZLrcCdVGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure images have shape (28, 28, 1)\n",
        "X_train = np.expand_dims(X_train, -1)\n",
        "X_test = np.expand_dims(X_test, -1)"
      ],
      "metadata": {
        "id": "Yj3CFPIVdYd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# define data preparation\n",
        "datagen = ImageDataGenerator(rotation_range = 20)\n",
        "# configure batch size and retrieve one batch of images\n",
        "classes = [0, 2, 3, 4, 5, 6, 8, 9]\n",
        "i=0\n",
        "x_train_new = np.ndarray(shape=(40296,28, 28, 1), dtype=float)\n",
        "y_train_new = np.ndarray(shape=(40296,), dtype=int)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=1, shuffle=True):\n",
        "    if(y_batch[0] in classes):\n",
        "      x_train_new[i] = X_batch\n",
        "      y_train_new[i] = y_batch\n",
        "      i += 1\n",
        "      if i > 40295:\n",
        "        break\n",
        "    else:\n",
        "      continue\n",
        "print(x_train_new.max())\n",
        "print(x_train_new.min())\n",
        "print(x_train_new.shape)\n",
        "print(y_train_new.shape)\n",
        "print(x_train_new.max())\n",
        "print(x_train_new.min())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndf0AVc_z33c",
        "outputId": "be86c3de-d55c-4d9d-c97b-01f1857bc8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n",
            "(40296, 28, 28, 1)\n",
            "(40296,)\n",
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [4, 8]\n",
        "i=0\n",
        "x_train_new2 = np.ndarray(shape=(10000,28, 28, 1), dtype=float)\n",
        "y_train_new2 = np.ndarray(shape=(10000,), dtype=int)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=1, shuffle=True):\n",
        "    if(y_batch[0] in classes):\n",
        "      x_train_new2[i] = X_batch\n",
        "      y_train_new2[i] = y_batch\n",
        "      i += 1\n",
        "      if i > 9999:\n",
        "        break\n",
        "    else:\n",
        "      continue\n",
        "print(x_train_new2.max())\n",
        "print(x_train_new2.min())\n",
        "print(x_train_new2.shape)\n",
        "print(y_train_new2.shape)\n",
        "print(x_train_new2.max())\n",
        "print(x_train_new2.min())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2Eh8RQRKTpX",
        "outputId": "eab3233d-fe81-4cfb-c476-ec21c95e66ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n",
            "(10000, 28, 28, 1)\n",
            "(10000,)\n",
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate((X_train, x_train_new), axis=0)\n",
        "#X_train = np.concatenate((X_train, x_train_new2), axis=0)\n",
        "\n",
        "y_train = np.concatenate((y_train, y_train_new), axis=0)\n",
        "#y_train = np.concatenate((y_train, y_train_new2), axis=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq3XiZdk_ktr",
        "outputId": "e4ff9576-6c12-48b0-a2b3-dc7d41ad5061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(107456, 28, 28, 1)\n",
            "(107456,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = np.zeros((10,), dtype=int)\n",
        "print(y_train[0])\n",
        "for val in y_train:\n",
        "    val = val.astype(np.int)\n",
        "    count[val]+=1\n",
        "print(count*100/sum(count))\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhvuigalI75A",
        "outputId": "30915b13-cbd2-4310-9f98-fd2b9074233e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-65056bf68f66>:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  val = val.astype(np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.91423466 12.5483919  10.97844699 11.28834127  5.38452948  9.97989875\n",
            " 10.89283055 11.66058666  5.39569684 10.95704288]\n",
            "[11728 13484 11797 12130  5786 10724 11705 12530  5798 11774]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "Zvd8aZcLdfwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", kernel_initializer='he_uniform'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", kernel_initializer='he_uniform'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(100, activation=\"relu\", kernel_initializer='he_uniform'),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHdCTudSBQ4M",
        "outputId": "806abc9b-3aa9-4f99-9ce8-b16ab548dd36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               160100    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 179926 (702.84 KB)\n",
            "Trainable params: 179926 (702.84 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "class_weights = compute_class_weight(class_weight = \"balanced\", classes = np.unique(dataset['y_train']), y = dataset['y_train'])\n",
        "class_weights = [round(w, 2) for w in class_weights]\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"categorical_accuracy\"])\n",
        "print(X_train.max())\n",
        "print(X_train.min())\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weights)\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(score)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK4JKrjmBV_h",
        "outputId": "822d85f5-9c37-422f-879a-19379ec0e4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n",
            "Epoch 1/10\n",
            "840/840 [==============================] - 83s 98ms/step - loss: 0.1984 - categorical_accuracy: 0.9443\n",
            "Epoch 2/10\n",
            "840/840 [==============================] - 82s 97ms/step - loss: 0.0698 - categorical_accuracy: 0.9801\n",
            "Epoch 3/10\n",
            "840/840 [==============================] - 81s 96ms/step - loss: 0.0503 - categorical_accuracy: 0.9862\n",
            "Epoch 4/10\n",
            "840/840 [==============================] - 81s 96ms/step - loss: 0.0414 - categorical_accuracy: 0.9882\n",
            "Epoch 5/10\n",
            " 96/840 [==>...........................] - ETA: 1:14 - loss: 0.0310 - categorical_accuracy: 0.9915"
          ]
        }
      ]
    }
  ]
}